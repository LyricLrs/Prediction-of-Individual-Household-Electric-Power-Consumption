{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv('2yrs_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "df = df.sort_values('Datetime')\n",
    "data = df['Global_active_power'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MultiStepTimeSeriesGenerator():\n",
    "    \"\"\"\n",
    "    Copied and edited from https://www.tensorflow.org/tutorials/structured_data/time_series\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 input_width, \n",
    "                 label_width, \n",
    "                 shift,\n",
    "                 df,\n",
    "                 batch_size):\n",
    "\n",
    "        # Work out the window parameters.\n",
    "        self.input_width       = input_width\n",
    "        self.label_width       = label_width\n",
    "        self.shift             = shift\n",
    "        self.batch_size        = batch_size\n",
    "        self.total_window_size = input_width + label_width\n",
    "        self.input_slice       = slice(0, input_width)\n",
    "        self.labels_slice      = slice(self.total_window_size - self.label_width, None)\n",
    "        \n",
    "        # Preprocess the raw data into datasets\n",
    "        val_split = 0.2\n",
    "        self.train_df = df[0:int((len(df)-N_STEPS_OUT)*(1-val_split))]\n",
    "        self.val_df = df[int((len(df)-N_STEPS_OUT)*(1-val_split))-N_STEPS_IN:-N_STEPS_OUT]\n",
    "        self.test_df = df[-(N_STEPS_IN + N_STEPS_OUT):]\n",
    "\n",
    "        self.train = self.make_dataset(self.train_df)\n",
    "        self.val   = self.make_dataset(self.val_df)\n",
    "        self.test  = self.make_dataset(self.test_df)\n",
    "\n",
    "    def split_window(self, features):\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "\n",
    "        labels = tf.stack([labels[:, :, 0]], axis = -1)\n",
    "    \n",
    "        # Slicing doesn't preserve static shape information, so set the shapes\n",
    "        # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype = np.float32)\n",
    "        ds = tf.keras.utils.timeseries_dataset_from_array(data            = data,\n",
    "                                                          targets         = None,\n",
    "                                                          sequence_length = self.total_window_size,\n",
    "                                                          sequence_stride = 1,\n",
    "                                                          shuffle         = False,\n",
    "                                                          batch_size      = self.batch_size)\n",
    "\n",
    "        ds = ds.map(self.split_window)\n",
    "\n",
    "        return ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STEPS_IN = 24\n",
    "N_STEPS_OUT = 12\n",
    "N_EPOCHS = 20   \n",
    "BATCH_SIZE = 32\n",
    "time_series_dataset = MultiStepTimeSeriesGenerator(input_width = N_STEPS_IN, \n",
    "                                                   label_width = N_STEPS_OUT, \n",
    "                                                   shift       = 1, \n",
    "                                                   df          = data_scaled, \n",
    "                                                   batch_size  = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_and_predictions(y_pred, history, n_epochs, feature_df):\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "    # Plot training/validation loss\n",
    "    ax[0].plot(history.history['loss'], label='Training Loss')\n",
    "    ax[0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax[0].set_title('Loss Curve')\n",
    "    ax[0].set_xlabel('Epochs')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Plot predictions against actual values\n",
    "    y_actual = feature_df[-len(y_pred):]  # Match size of predictions\n",
    "    ax[1].plot(y_actual.index, y_actual.values, label='Actual', color='blue')\n",
    "    ax[1].plot(y_actual.index, y_pred.reshape(-1), label='Predicted', color='red')\n",
    "    ax[1].set_title('Predictions vs Actual')\n",
    "    ax[1].set_xlabel('Time')\n",
    "    ax[1].set_ylabel('Value')\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return ax\n",
    "\n",
    "def evaluate_baseline(model, df, n_epochs = N_EPOCHS, verbose = 0):\n",
    "    # Compile model\n",
    "    model.compile(loss      = tf.losses.MeanSquaredError(),\n",
    "                  optimizer = tf.optimizers.Adam(),\n",
    "                  metrics   = [tf.metrics.MeanAbsoluteError()])\n",
    "    \n",
    "    # Create datasets from dataframe\n",
    "    time_series_dataset = MultiStepTimeSeriesGenerator(input_width = N_STEPS_IN, \n",
    "                                              label_width = N_STEPS_OUT, \n",
    "                                              shift       = 1, \n",
    "                                              df          = df, \n",
    "                                              batch_size  = BATCH_SIZE)\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(time_series_dataset.train, \n",
    "                        validation_data = time_series_dataset.val,\n",
    "                        epochs          = n_epochs,\n",
    "                        batch_size      = BATCH_SIZE, \n",
    "                        verbose         = verbose, \n",
    "                        callbacks       = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n",
    "                                                                           patience = 4),\n",
    "                        shuffle         = False)\n",
    "\n",
    "    # Make predictions on test set\n",
    "    y_pred = model.predict(time_series_dataset.test, verbose=0)\n",
    "    test_score = mean_squared_error(list(time_series_dataset.test.as_numpy_iterator())[0][1][0], y_pred.reshape(-1))\n",
    "    test_score = np.round(test_score, 5)\n",
    "    \n",
    "    # Plot predictions\n",
    "    ax = plot_loss_and_predictions(y_pred, history, n_epochs, df[['feature']])\n",
    "\n",
    "    return test_score, ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', return_sequences=True, input_shape=(N_STEPS_IN, 1)),\n",
    "    LSTM(32, activation='relu'),\n",
    "    Dense(N_STEPS_OUT) \n",
    "])\n",
    "\n",
    "test_score, ax = evaluate_baseline(model, data_scaled, n_epochs=N_EPOCHS, verbose=1)\n",
    "\n",
    "print(f\"Test Mean Squared Error: {test_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
